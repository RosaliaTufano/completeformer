{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: API details.\n",
    "output-file: models.html\n",
    "title: Models\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 16:12:45.096980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 16:12:46.059221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-03-09 16:12:46.059905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-03-09 16:12:46.059912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import evaluate\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# from datasets import load_metric\n",
    "from pathlib import Path\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "from x_transformers import XTransformer\n",
    "from x_transformers.autoregressive_wrapper import top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "config = {\n",
    "    \"max_epochs\": 10,\n",
    "    \"length\": \"short\",\n",
    "    \"position_type\": \"sinusoidal\",\n",
    "    \"dim\": 512,\n",
    "    \"enc_max_len\": 512,\n",
    "    \"enc_layers\": 6,\n",
    "    \"enc_heads\": 8,\n",
    "    \"dec_max_len\": 256,\n",
    "    \"dec_layers\": 6,\n",
    "    \"dec_heads\": 8,\n",
    "}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/codet5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "# Code from: https://github.com/huggingface/transformers/blob/master/examples/research_projects/codeparrot/scripts/codeparrot_training.py#L113\n",
    "def get_grouped_params(model, weight_decay, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [\n",
    "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
    "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Completeformer(pl.LightningModule):\n",
    "    \"\"\"\n",
    "        Completeformer is a T5 based encoder-decoder model that uses the Alibi positional embedding heuristic for the decoder.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        max_epochs,\n",
    "        length,\n",
    "        position_type=\"sinusoidal\",\n",
    "        dim=512,\n",
    "        enc_max_len=1024,\n",
    "        enc_layers=6,\n",
    "        enc_heads=8,\n",
    "        dec_max_len=128,\n",
    "        dec_layers=6,\n",
    "        dec_heads=8,\n",
    "        lr=1e-4,\n",
    "        num_warmup_steps=2_000,\n",
    "        weight_decay=0.1,\n",
    "        grad_accum=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.length = length\n",
    "        self.position_type = position_type\n",
    "        assert self.position_type in [\"sinusoidal\", \"rotary\", \"alibi\", \"relative\", \"dynamic\"], f\"Position type {self.position_type} not supported.\"\n",
    "        if self.position_type == \"sinusoidal\":\n",
    "            self.model = XTransformer(\n",
    "                dim = dim,\n",
    "                tie_token_embeds = True,\n",
    "                return_tgt_loss = True,\n",
    "                use_abs_pos_emb = False,\n",
    "                scaled_sinu_pos_emb = True,\n",
    "                enc_scaled_sinu_pos_emb = True,\n",
    "                enc_num_tokens = len(tokenizer),\n",
    "                enc_depth = enc_layers,\n",
    "                enc_heads = enc_heads,\n",
    "                enc_max_seq_len = enc_max_len,\n",
    "                dec_num_tokens = len(tokenizer),\n",
    "                dec_depth = dec_layers,\n",
    "                dec_heads = dec_heads,\n",
    "                dec_max_seq_len = dec_max_len,\n",
    "                dec_scaled_sinu_pos_emb = True\n",
    "            )\n",
    "        elif self.position_type == \"rotary\":\n",
    "            self.model = XTransformer(\n",
    "                dim = dim,\n",
    "                tie_token_embeds = True,\n",
    "                return_tgt_loss = True,\n",
    "                enc_rotary_pos_emb = True,\n",
    "                enc_num_tokens = len(tokenizer),\n",
    "                enc_depth = enc_layers,\n",
    "                enc_heads = enc_heads,\n",
    "                enc_max_seq_len = enc_max_len,\n",
    "                dec_num_tokens = len(tokenizer),\n",
    "                dec_depth = dec_layers,\n",
    "                dec_heads = dec_heads,\n",
    "                dec_max_seq_len = dec_max_len,\n",
    "                dec_rotary_xpos = True\n",
    "            )\n",
    "        elif self.position_type == \"alibi\":\n",
    "            self.model = XTransformer(\n",
    "                dim = dim,\n",
    "                tie_token_embeds = True,\n",
    "                return_tgt_loss = True,\n",
    "                enc_alibi_pos_emb = True,\n",
    "                enc_num_tokens = len(tokenizer),\n",
    "                enc_depth = enc_layers,\n",
    "                enc_heads = enc_heads,\n",
    "                enc_max_seq_len = enc_max_len,\n",
    "                dec_num_tokens = len(tokenizer),\n",
    "                dec_depth = dec_layers,\n",
    "                dec_heads = dec_heads,\n",
    "                dec_max_seq_len = dec_max_len,\n",
    "                dec_alibi_pos_emb = True\n",
    "            )\n",
    "        elif self.position_type == \"relative\":\n",
    "            self.model = XTransformer(\n",
    "                dim = dim,\n",
    "                tie_token_embeds = True,\n",
    "                return_tgt_loss = True,\n",
    "                enc_rel_pos_bias = True,\n",
    "                enc_num_tokens = len(tokenizer),\n",
    "                enc_depth = enc_layers,\n",
    "                enc_heads = enc_heads,\n",
    "                enc_max_seq_len = enc_max_len,\n",
    "                dec_num_tokens = len(tokenizer),\n",
    "                dec_depth = dec_layers,\n",
    "                dec_heads = dec_heads,\n",
    "                dec_max_seq_len = dec_max_len,\n",
    "                dec_rel_pos_bias = True\n",
    "            )\n",
    "        elif self.position_type == \"dynamic\":\n",
    "            self.model = XTransformer(\n",
    "                dim = dim,\n",
    "                tie_token_embeds = True,\n",
    "                return_tgt_loss = True,\n",
    "                enc_dynamic_pos_bias = True,\n",
    "                enc_dynamic_pos_bias_log_distance = False,\n",
    "                enc_num_tokens = len(tokenizer),\n",
    "                enc_depth = enc_layers,\n",
    "                enc_heads = enc_heads,\n",
    "                enc_max_seq_len = enc_max_len,\n",
    "                dec_num_tokens = len(tokenizer),\n",
    "                dec_depth = dec_layers,\n",
    "                dec_heads = dec_heads,\n",
    "                dec_max_seq_len = dec_max_len,\n",
    "                dec_dynamic_pos_bias = True,\n",
    "                dec_dynamic_pos_bias_log_distance = False\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.grad_accum = grad_accum\n",
    "\n",
    "        # Get metrics for testing\n",
    "        self.bleu_metric = evaluate.load(\"bleu\")\n",
    "        self.chrf_metric = evaluate.load(\"chrf\")\n",
    "        self.em_metric = evaluate.load(\"exact_match\")\n",
    "        self.leven_dist_metric = evaluate.load(\"ncoop57/levenshtein_distance\")\n",
    "        self.meteor_metric = evaluate.load(\"meteor\")\n",
    "        self.rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "        # Ignore padding token in loss calculation\n",
    "        self.model.decoder.ignore_index = tokenizer.pad_token_id\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, srcs, tgts, srcs_mask):\n",
    "        return self.model(srcs, tgts, mask=srcs_mask)\n",
    "\n",
    "    def on_train_start(self):\n",
    "        # Create a table to store the generated samples\n",
    "        self.table = wandb.Table(data=[], columns=[\"input\", \"completion\", \"step\"])\n",
    "\n",
    "    def on_train_end(self):\n",
    "        # Save the generated samples\n",
    "        self.logger.experiment.log({\"generated_samples\": self.table})\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        srcs = batch[\"input_ids\"]\n",
    "        tgts = batch[\"labels\"]\n",
    "\n",
    "        srcs_mask = batch[\"attention_mask\"].bool()\n",
    "\n",
    "        loss = self(srcs, tgts, srcs_mask)\n",
    "        self.log(\n",
    "            \"trn_loss\", \n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            logger=True\n",
    "        )\n",
    "        opt = self.optimizers()\n",
    "        lr = opt.param_groups[0][\"lr\"]\n",
    "        self.log(\"lr\", lr, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        # Generate a sample and add it to the table\n",
    "        text = \"def bubbleSort(arr): <TAB>n = len(arr) <TAB><MASK>\"\n",
    "        prediction = self.generate(text, self.tokenizer)\n",
    "        completion = text.replace(\"<MASK>\", prediction)\n",
    "        self.table.add_data(text, completion, self.global_step)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        srcs = batch[\"input_ids\"]\n",
    "        tgts = batch[\"labels\"]\n",
    "\n",
    "        srcs_mask = batch[\"attention_mask\"].bool()\n",
    "        loss = self(srcs, tgts, srcs_mask)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        srcs = batch[\"input_ids\"].to(self.device)\n",
    "        tgts = batch[\"labels\"].to(self.device)\n",
    "\n",
    "        srcs_mask = batch[\"attention_mask\"].bool().to(self.device)\n",
    "        loss = self(srcs, tgts, srcs_mask)\n",
    "        self.log(\"tst_loss\", loss, on_epoch=True, logger=True)\n",
    "\n",
    "        num_tokens = torch.sum(tgts != self.tokenizer.pad_token_id, dim=1)\n",
    "        max_tokens = torch.max(num_tokens).item() - 1 # -1 for the BOS token\n",
    "        start_tokens = (torch.ones((batch[\"input_ids\"].shape[0], 1)) * self.tokenizer.bos_token_id).long().to(self.device)\n",
    "\n",
    "        samples = self.model.generate(srcs, start_tokens, max_tokens, mask=srcs_mask, filter_logits_fn=top_p)\n",
    "        new_samples, new_tgts = [], []\n",
    "        for i in range(0, num_tokens.shape[0]):\n",
    "            # Trim samples and targets to EOS token\n",
    "            sample_eos = torch.where(samples[i] == self.tokenizer.eos_token_id)[0]\n",
    "            tgt_eos = torch.where(tgts[i] == self.tokenizer.eos_token_id)[0]\n",
    "            if sample_eos.shape[0] > 0:\n",
    "                new_sample = samples[i][:sample_eos[0]]\n",
    "            else:\n",
    "                new_sample = samples[i]\n",
    "            \n",
    "            if tgt_eos.shape[0] > 0:\n",
    "                new_tgt = tgts[i][:tgt_eos[0]]\n",
    "            else:\n",
    "                new_tgt = tgts[i]\n",
    "            \n",
    "            new_samples.append(new_sample.tolist())\n",
    "            new_tgts.append(new_tgt.tolist())\n",
    "\n",
    "        decoded_preds = self.tokenizer.batch_decode(new_samples, skip_special_tokens=True)\n",
    "        decoded_labels = self.tokenizer.batch_decode(new_tgts, skip_special_tokens=True)\n",
    "        self.bleu_metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "        )\n",
    "        self.chrf_metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels\n",
    "        )\n",
    "        self.em_metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels\n",
    "        )\n",
    "        self.leven_dist_metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "        )\n",
    "        self.meteor_metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels\n",
    "        )\n",
    "        self.rouge_metric.add_batch(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "        )\n",
    "\n",
    "    def test_epoch_end(self, training_step_outputs):\n",
    "        bleu_score = self.bleu_metric.compute(tokenizer=lambda x: self.tokenizer.tokenize(x))\n",
    "        self.log(f\"bleu_{self.length}\", bleu_score[\"bleu\"], on_epoch=True, logger=True)\n",
    "\n",
    "        chrf_score = self.chrf_metric.compute()\n",
    "        self.log(f\"chrf_{self.length}\", chrf_score[\"score\"], on_epoch=True, logger=True)\n",
    "\n",
    "        em_score = self.em_metric.compute()\n",
    "        self.log(f\"exact_match_{self.length}\", em_score[\"exact_match\"], on_epoch=True, logger=True)\n",
    "\n",
    "        leven_dist_score = self.leven_dist_metric.compute(tokenizer=lambda x: self.tokenizer.tokenize(x), normalize=True)\n",
    "        self.log(f\"leven_dist_{self.length}\",  leven_dist_score[\"levenshtein_distance\"], on_epoch=True, logger=True)\n",
    "\n",
    "        meteor_score = self.meteor_metric.compute()\n",
    "        self.log(f\"meteor_{self.length}\", meteor_score[\"meteor\"], on_epoch=True, logger=True)\n",
    "\n",
    "        rouge_score = self.rouge_metric.compute(tokenizer=lambda x: self.tokenizer.tokenize(x))\n",
    "        self.log(f\"rouge_{self.length}\", rouge_score[\"rougeL\"], on_epoch=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Setup the Adam optimizer with a Cosine LR scheduler with warm restarts\n",
    "        optimizer = AdamW(get_grouped_params(self.model, self.weight_decay), lr=self.lr)\n",
    "        lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=self.num_warmup_steps,\n",
    "            num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1\n",
    "            },\n",
    "        }\n",
    "    \n",
    "    def total_steps(self) -> int:\n",
    "        \"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"\n",
    "        dataset_size = len(self.trainer.datamodule.train_dataloader())\n",
    "        return dataset_size * self.hparams.max_epochs\n",
    "\n",
    "    def generate(self, text, tokenizer, num_tokens=32, decode=True):\n",
    "        \"\"\"\n",
    "            Generate a sample from the model.\n",
    "\n",
    "            Args:\n",
    "                text (str): The text to generate from.\n",
    "                tokenizer (Tokenizer): The tokenizer to use.\n",
    "                num_tokens (int): The number of tokens to generate.\n",
    "                decode (bool): Whether to decode the output.\n",
    "            Returns:\n",
    "                sample (str or torch.Tensor): The generated sample as a string or list of tokens (if decode=True).\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        t = tokenizer(text, return_tensors=\"pt\")\n",
    "        src = t[\"input_ids\"].to(self.device)\n",
    "        src_mask = t[\"attention_mask\"].bool().to(self.device)\n",
    "        start_tokens = (torch.ones((1, 1)) * tokenizer.bos_token_id).long().to(self.device)\n",
    "        sample = self.model.generate(src, start_tokens, num_tokens, mask=src_mask, filter_logits_fn=top_p)\n",
    "\n",
    "        return tokenizer.decode(sample[0], skip_special_tokens=True) if decode else sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nathan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nathan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# write some unit tests for the model\n",
    "model = Completeformer(tokenizer, **config)\n",
    "\n",
    "# evaluate the number of parameters\n",
    "TOTAL_PARAMS = 110_301_896\n",
    "model_parameters = sum(p.numel() for p in model.parameters())\n",
    "assert model_parameters == TOTAL_PARAMS\n",
    "\n",
    "# evaluate that the model can generate a sample\n",
    "text = \"def bubble_sort(arr):<MASK>\"\n",
    "prediction = model.generate(text, tokenizer, num_tokens=32)\n",
    "assert type(prediction) == str\n",
    "\n",
    "prediction = model.generate(text, tokenizer, num_tokens=32, decode=False)\n",
    "assert type(prediction) == torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
